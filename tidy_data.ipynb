{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e904dd71-d285-46e2-b369-dcb1cf076ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24dbbd0-0781-4685-9c0f-80d5595786af",
   "metadata": {},
   "source": [
    "# 1. Dictionary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3c6aaf-cf5e-4c74-ab62-326f0bfc5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devious way of reading txt straight to Series\n",
    "# (sep is what it is so it only gets one column)\n",
    "word_list = pd.read_csv(\"datasets/Words.txt\", sep=\"&\"*int(1e6), engine=\"python\", header=None)[0].dropna()\n",
    "word_list = word_list[\n",
    "    word_list.str.islower() # delete proper nouns\n",
    "    & word_list.str.isalpha() # delete things with punctuation\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e256fc4-6218-4f78-99d6-48afdd4544d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124069           englyns\n",
       "309350           predoom\n",
       "286338        passometer\n",
       "445850           vagally\n",
       "357860     semiexecutive\n",
       "299851       planetogeny\n",
       "69211              choko\n",
       "380574           squaddy\n",
       "106928       diplocardia\n",
       "90437     cryobiological\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32e2348-863e-44a0-9f34-f0edaa835ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_set = set()\n",
    "for word in word_list:\n",
    "    char_set |= set(word)\n",
    "\"\".join(sorted(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ff7a38a-76f0-4261-ba47-2af45fbb8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list.to_csv(\"datasets/cleaned/words.csv\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea2785-8e5f-4379-b477-80225681de5d",
   "metadata": {},
   "source": [
    "# 2. Baseball players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cab2cc7-7146-4c5f-b706-4a213d35fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"nameFirst\", \"nameLast\", \"birthYear\", \"birthCountry\", \"playerID\"]\n",
    "renamed = [\"first_name\", \"last_name\", \"birth_year\", \"birth_country\", \"id\"]\n",
    "players = pd.read_csv(\"datasets/People.csv\")[cols].dropna().rename(columns=dict(zip(cols, renamed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cdcd0b-a0ab-40b8-9fae-2634c08c1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_diacritics(name_ser):\n",
    "    # Often you have a name with an e with an accent on that\n",
    "    # that will be a nuisance for the model, so turn it to an e with no accent\n",
    "    normalised = name_ser.apply(lambda x: unicodedata.normalize(\"NFD\", x))\n",
    "    without_diacritics = normalised.apply(lambda x: \"\".join([c for c in x if unicodedata.category(c) != \"Mn\"]))\n",
    "    return without_diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4042d9-e1e4-4852-bcf3-11d1dc851048",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [\"first\", \"last\"]:\n",
    "    players[f\"edited_{p}\"] = replace_diacritics(players[f\"{p}_name\"]).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d31a458-25d6-4178-bf4b-6e336d8d078d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" '-.abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(list(players[[\"edited_first\", \"edited_last\"]].sum().sum()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4915b2c8-013a-40ce-9036-a66c44f8cc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"datasets/cleaned/players.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3de39-6d11-4282-90e7-11a4f42fe95d",
   "metadata": {},
   "source": [
    "# 3. Star wars characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "16ebe05d-53c3-47fe-a567-3b6cc1d95112",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = replace_diacritics(pd.read_csv(\"datasets/full_sw_names.csv\")[\"name\"])\n",
    "allowed_chars = \" '-.abcdefghijklmnopqrstuvwxyz\"\n",
    "legal_names = names[names.str.lower().apply(lambda s: set(s).issubset(allowed_chars))] # i.e., no numbers etc\n",
    "proper_names = legal_names[~legal_names.str.contains(r' [a-z]', regex=True)] # i.e., nothing like \"King of X\"\n",
    "identified = proper_names[~(proper_names.str[:len(\"Unidentified\")] == \"Unidentified\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1c891fff-4f08-42dc-b80e-ab046a409ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19522    Zubindi Ebsuk\n",
       "42588            Tenek\n",
       "10806     Luha Kellaro\n",
       "29445       Falco Sang\n",
       "18361       Jaden Dala\n",
       "45947     Rachel Gutek\n",
       "18903       Emf Diddar\n",
       "25459       Mankuskett\n",
       "37674       Crank Flat\n",
       "38266         Eradicus\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identified.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cf3a37cc-f1aa-4520-a681-f941f81802d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified = replace_diacritics(identified).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "12b7e6b9-5abb-42f7-9848-024f520d9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "identified.to_csv(\"datasets/cleaned/characters.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a9a2d-dd43-470f-a2a8-f1391a20d61e",
   "metadata": {},
   "source": [
    "# Get more info about players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5bbfcbbe-bbd6-4645-be47-3bd1bfd0ce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybaseball\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "05ddb722-052b-4660-baf6-355f2dff619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████▋                     | 118/246 [00:28<00:30,  4.14it/s]/Users/markrothery/miniforge3/envs/fastai_env/lib/python3.12/site-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
      "100%|█████████████████████████████████████████| 246/246 [00:56<00:00,  4.36it/s]\n",
      "/Users/markrothery/miniforge3/envs/fastai_env/lib/python3.12/site-packages/pybaseball/statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    }
   ],
   "source": [
    "pybaseball.cache.enable()\n",
    "stats = pybaseball.statcast(start_dt=\"2025-01-01\", end_dt=\"2025-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d9985af-0d53-4441-b062-d9b0e56794c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats[\"batter_team\"] = np.where(\n",
    "    stats[\"inning_topbot\"] == \"Top\",\n",
    "    stats[\"away_team\"],\n",
    "    stats[\"home_team\"]\n",
    ")\n",
    "stats[\"pitcher_team\"] = np.where(\n",
    "    stats[\"inning_topbot\"] == \"Top\",\n",
    "    stats[\"home_team\"],\n",
    "    stats[\"away_team\"]\n",
    ")\n",
    "batters = stats[[\"batter\", \"batter_team\"]].value_counts().reset_index().drop(\"count\", axis=1).rename(\n",
    "    columns={\"batter\": \"player\", \"batter_team\": \"team\"}\n",
    ")\n",
    "pitchers = stats[[\"pitcher\", \"pitcher_team\"]].value_counts().reset_index().drop(\"count\", axis=1).rename(\n",
    "    columns={\"pitcher\": \"player\", \"pitcher_team\": \"team\"}\n",
    ")\n",
    "total = pd.concat([batters, pitchers], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "017c358b-58d5-454d-83d3-ef3275863e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_df = pybaseball.playerid_reverse_lookup(total[\"player\"], key_type=\"mlbam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a163adbb-0f66-4a15-927d-de330d1b9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = total.rename(columns={\"player\": \"key_mlbam\"}).merge(lookup_df).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0068a52e-b5c4-4c4b-b10f-9a9dac760b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[\"name\"] = replace_diacritics(combined[\"name_first\"] + \" \" + combined[\"name_last\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "535b427d-d068-4b89-8d01-406e69c6663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_csv(\"datasets/cleaned/team_info.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
